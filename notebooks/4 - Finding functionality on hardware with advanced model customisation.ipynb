{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f503656",
   "metadata": {},
   "source": [
    "# Example: Advanced model customisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc96bbd3",
   "metadata": {},
   "source": [
    "This notebook covers an example on how to find functionality in hardware for a more complex task that requires more advanced usage of custom models. It will cover an example with the famous LeNet neural network architecture for the classical classification benchmark task of digit recognition with the Modified National Institute of Standards and Technology (MNIST) dataset.  \n",
    "\n",
    "\n",
    "**Prerequisites:**\n",
    "- You have a surrogate model from a DNPU model that is still connected to an NI device in the lab\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a752a873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"4.finding_functionality/cnn_main.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "# Image from https://www.codexa.net/cnn-mnist-keras-beginner/\n",
    "Image(url= \"4.finding_functionality/cnn_main.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f4354a",
   "metadata": {},
   "source": [
    "## 1. Having a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b127914b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "\n",
    "# Downloading dataset in ./tmp/data\n",
    "dataset_example = MNIST('./tmp/data', train=True, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f19f5e",
   "metadata": {},
   "source": [
    "### 1.1 Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab2411c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ./tmp/data\n",
       "    Split: Train"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8fe7500",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_dataset_element = dataset_example[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57aa8402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(first_dataset_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecf73a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=L size=28x28>, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_dataset_element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a812bfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_img = first_dataset_element[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83db534f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAElEQVR4nGNgGMyAWUhIqK5jvdSy/9/rGRgYGFhgEnJsVjYCwQwMDAxPJgV+vniQgYGBgREqZ7iXH8r6l/SV4dn7m8gmCt3++/fv37/Htn3/iMW+gDnZf/+e5WbQnoXNNXyMs/5GoQoxwVmf/n9kSGFiwAW49/11wynJoPzx4YIcRlyygR/+/i2XxCWru+vv32nSuGQFYv/83Y3b4p9/fzpAmSyoMnohpiwM1w5h06Q+5enfv39/bcMiJVF09+/fv39P+mFKiTtd/fv3799jgZiBJLT69t+/f/8eDuDEkDJf8+jv379/v7Ryo4qzMDAwMAQGMjBc3/y35wM2V1IfAABFF16Aa0wAOwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6880a64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "first_img_np = np.array(first_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fed900e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_img_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "959eb6ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_img_np.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58f99e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_img_np.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c267b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_img_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f5a7cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "        0.07058824, 0.49411765, 0.53333333, 0.68627451, 0.10196078,\n",
       "        0.65098039, 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.11764706, 0.14117647,\n",
       "        0.36862745, 0.60392157, 0.66666667, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.88235294, 0.6745098 ,\n",
       "        0.99215686, 0.94901961, 0.76470588, 0.25098039, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.19215686, 0.93333333, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.98431373, 0.36470588, 0.32156863,\n",
       "        0.32156863, 0.21960784, 0.15294118, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.07058824, 0.85882353, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.77647059,\n",
       "        0.71372549, 0.96862745, 0.94509804, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31372549, 0.61176471,\n",
       "        0.41960784, 0.99215686, 0.99215686, 0.80392157, 0.04313725,\n",
       "        0.        , 0.16862745, 0.60392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "        0.00392157, 0.60392157, 0.99215686, 0.35294118, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.54509804, 0.99215686, 0.74509804, 0.00784314,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04313725, 0.74509804, 0.99215686, 0.2745098 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.1372549 , 0.94509804, 0.88235294,\n",
       "        0.62745098, 0.42352941, 0.00392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31764706, 0.94117647,\n",
       "        0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.17647059,\n",
       "        0.72941176, 0.99215686, 0.99215686, 0.58823529, 0.10588235,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0627451 , 0.36470588, 0.98823529, 0.99215686, 0.73333333,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.97647059, 0.99215686, 0.97647059,\n",
       "        0.25098039, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
       "        0.50980392, 0.71764706, 0.99215686, 0.99215686, 0.81176471,\n",
       "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15294118, 0.58039216, 0.89803922,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.71372549,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09411765, 0.44705882, 0.86666667, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.78823529, 0.30588235, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09019608, 0.25882353,\n",
       "        0.83529412, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.77647059, 0.31764706, 0.00784314, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07058824, 0.67058824, 0.85882353, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.76470588, 0.31372549,\n",
       "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.21568627,\n",
       "        0.6745098 , 0.88627451, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.95686275, 0.52156863, 0.04313725, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.53333333,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.83137255, 0.52941176,\n",
       "        0.51764706, 0.0627451 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_img_np/255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e02b040",
   "metadata": {},
   "source": [
    "### 1.2 Image modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6380da4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_values = []\n",
    "desired_label = 5\n",
    "for i in range(len(dataset_example)):\n",
    "    current = dataset_example[i]\n",
    "    if current[1] == desired_label:\n",
    "        labelled_values.append(np.array(current[0]))\n",
    "\n",
    "labelled_values = np.array(labelled_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "187c86d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5421, 28, 28)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40b9d901",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labelled_values' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22180\\758264209.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabelled_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'labelled_values' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.imshow(labelled_values.mean(0),cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54f4879",
   "metadata": {},
   "source": [
    "### 1.3 Labels and One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52aac755",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_label = first_dataset_element[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170f8bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9948f292",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17932\\1132979489.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfirst_label_one_hot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfirst_label_one_hot\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfirst_label\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfirst_label_one_hot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "first_label_one_hot = np.zeros(10)\n",
    "first_label_one_hot[first_label] = 1\n",
    "first_label_one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0314e66",
   "metadata": {},
   "source": [
    "Note that the model should also produce outputs that are a vector with the same dimension as the number of labels. In this case 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3c05a5",
   "metadata": {},
   "source": [
    "## 2. Understanding loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895919fd",
   "metadata": {},
   "source": [
    "The cross entropy loss function can be decomposed into Softmax and Negative Likelihood. We can have a look at these concepts individually."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c42d8b8",
   "metadata": {},
   "source": [
    "### 2.1 Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a1da1f",
   "metadata": {},
   "source": [
    "We want to represent the raw output of our model (logits) as a probability, for which it would need to satisfy the following conditions:\n",
    "- Each element in $\\hat{y_i}$ is in a range from 0 to 1. \n",
    "- All the elements of the output prediction vector $\\hat{y_i}$ add to 1.\n",
    "- It maintains this ratio when translating it into a probability. I.e. if a if one value in $\\hat{y_i}$ is greater, it should maintain its proportion. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58255332",
   "metadata": {},
   "source": [
    "In principle, we could try to satisfy these conditions by dividing each of the elements in the output vector prediction $\\hat{y_i}$ by the sum of all the elements in the same vector. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6828fa4",
   "metadata": {},
   "source": [
    "$ f({y_i}) = \\frac{\\hat{y_{ij}}}{\\sum_{j=0}^{n} \\hat{y_{ij}}} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ab8e161",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23016\\2753459116.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_i_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "y_i_hat = np.array([3,2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7d249c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = []\n",
    "for i in range(len(y_i_hat)):\n",
    "    f.append(y_i_hat[i] / y_i_hat.sum())\n",
    "    print(f[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbde5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(f).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451ea3ca",
   "metadata": {},
   "source": [
    "However, if we have negative values, we could end with NaN values. In order to maintain numerical stability, we can turn all negative values into positive ones we use the function $e^x$. Making the softmax function formula be: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14be853",
   "metadata": {},
   "source": [
    "$  f({y_i}) = \\frac{e^{\\hat{y_{ij}}}}{\\sum_{j=0}^{n} e^{\\hat{y_{ij}}}} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04ffa26b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_i_hat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23016\\1977547932.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_i_hat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_i_hat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_i_hat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_i_hat' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "f = []\n",
    "for i in range(len(y_i_hat)):\n",
    "    f.append( np.exp(y_i_hat[i]) / np.exp(y_i_hat).sum())\n",
    "    print(f[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "608cb428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np.array(f).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f79b43f",
   "metadata": {},
   "source": [
    "Where n is the number of classes in the dataset. $\\hat{y_i}$ is a prediction vector of the same size as the number of classes. The model should maintain the same vector lenghth as the target values. Remember that we have already seen an example of how target vectors look like for the number 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c71ccdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_label_one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e43d130",
   "metadata": {},
   "source": [
    "Finally, the division can be made more numerically stable (avoiding division by zero), when transformed into the log domain, where it would be a substraction. Therefore, \n",
    "it is not uncommon to use $log(f(y_i))$ instead. This other function is called log softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46217147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source from https://www.youtube.com/watch?v=RC_A9Tu99y4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bf9b7a",
   "metadata": {},
   "source": [
    "### 2.2 Maximum likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04aa493d",
   "metadata": {},
   "source": [
    "The goal of maximum likelihood is to find a distribution that maximises the likelihood of observing the outputs that are measured. Therefore, it assigns higher probabilities to models that are able to represent probabilities based on what was observed and picks the model that gives existing labels the highest probability. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee588067",
   "metadata": {},
   "source": [
    "To understand this better, let us assume that we have a simple perceptron  $\\hat{y}$ = $\\sigma$(W*x + b) that classifies four points (two blue and two red). Our particular prediction $\\hat{y}$ is equal to the probability of a particular point being labelled correctly $P$(blue) = $\\sigma$(W*x + b). Let us assume that you have two different models, giving you different probabilities for the same points. The first model is represented on the left of the image, and the second model is represented on the right of the image below. The images show the probability of being red in red, and the probability of being blue in blue. Note that the probability of being blue is one minus the probability of being red. Assuming that the points are independent events, then the probability for the whole arrangement is the product of the probabilities of each point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ceb1d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "# Image and lesson from https://www.youtube.com/watch?v=6nUUeQ9AeUA\n",
    "Image(url= \"4.finding_functionality/likelihood.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc73e190",
   "metadata": {},
   "outputs": [],
   "source": [
    "-(np.log(0.6) + np.log(0.2) + np.log(0.1) + np.log(0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f49f1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "-(np.log(0.7) + np.log(0.9) + np.log(0.8) + np.log(0.6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4f337f",
   "metadata": {},
   "source": [
    "### 2.3 Binary cross entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e66af9b",
   "metadata": {},
   "source": [
    "We want to maximise the likelihood of a model, but for this we need to multiply many points, which is inconvenient when we have huge datasets. In order to make products into sums, we use log functions. Probabilities are expressed in a range from 0 to 1, but on log scale these values are negative, so we take the negative log of the probabilities. Lower cross entropy is better than higher. The final formula for cross entropy is:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55610e3e",
   "metadata": {},
   "source": [
    "$- \\sum_{i=0}^{m} y_i . ln(p_i) + (1 - y_i) . ln(1 - p_i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1792cd2d",
   "metadata": {},
   "source": [
    "Where m is the number of elements in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e751a179",
   "metadata": {},
   "source": [
    "### 2.4 Multi-class cross entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa2c2a2",
   "metadata": {},
   "source": [
    "In a very similar way, this concept can be extended to multi classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c7635b",
   "metadata": {},
   "source": [
    "$- \\sum_{j=0}^{n} \\sum_{i=0}^{m} y_{ij} . ln(p_{ij})$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15728fcc",
   "metadata": {},
   "source": [
    "Where n is the number of classes in the dataset. $\\hat{y_i}$ is a prediction vector of the same size as the number of classes. The model should maintain the same vector lenghth as the target values. Remember that we have already seen an example of how target vectors look like for the number 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cdfbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_label_one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb7eeba",
   "metadata": {},
   "source": [
    "## 3. Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c10cd55",
   "metadata": {},
   "source": [
    "## 4. Preparing the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d096cf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from torch.jit.annotations import Optional\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "class MNISTDataModule(pl.LightningDataModule):\n",
    "    def __init__(self,\n",
    "                 data_dir: str = \"./tmp/data\",\n",
    "                 batch_size: int = 32,\n",
    "                 num_workers=4,\n",
    "                 pin_memory=False,\n",
    "                 split=[55000, 5000]):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.pin_memory = pin_memory\n",
    "        self.split = split\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # download\n",
    "        MNIST(self.data_dir, train=True, download=True)\n",
    "        MNIST(self.data_dir, train=False, download=True)\n",
    "\n",
    "    def setup(self, stage: Optional[str] = None):\n",
    "        if stage == 'fit' or stage is None:\n",
    "            mnist_full = MNIST(self.data_dir,\n",
    "                               train=True,\n",
    "                               transform=transforms.ToTensor())\n",
    "            self.mnist_train, self.mnist_val = random_split(\n",
    "                mnist_full, self.split)\n",
    "        if stage == 'test' or stage is None:\n",
    "            self.mnist_test = MNIST(self.data_dir,\n",
    "                                    train=False,\n",
    "                                    transform=transforms.ToTensor())\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.mnist_train,\n",
    "                          batch_size=self.batch_size,\n",
    "                          num_workers=self.num_workers,\n",
    "                          shuffle=True,\n",
    "                          pin_memory=self.pin_memory)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.mnist_val,\n",
    "                          batch_size=self.batch_size,\n",
    "                          num_workers=self.num_workers,\n",
    "                          shuffle=False,\n",
    "                          pin_memory=self.pin_memory)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.mnist_test,\n",
    "                          batch_size=self.batch_size,\n",
    "                          num_workers=self.num_workers,\n",
    "                          shuffle=False,\n",
    "                          pin_memory=self.pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "297b91fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchmetrics.functional.classification.accuracy import accuracy\n",
    "\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "class TrainerMNIST(pl.LightningModule):\n",
    "    def __init__(self, model, batch_size, learning_rate=1e-3):\n",
    "        super(TrainerMNIST, self).__init__()\n",
    "        self.name = 'mnist_trainer'\n",
    "        self.model = model\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        opt = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return opt\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "    \n",
    "    def shared_step(self, batch):\n",
    "        x, y = batch\n",
    "        preds = self(x)\n",
    "        loss = F.nll_loss(preds, y)\n",
    "        acc = accuracy(preds, y)\n",
    "        return loss, acc\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, acc = self.shared_step(batch)\n",
    "        self.log('loss_epoch', {'train': loss}, on_step=False, on_epoch=True)\n",
    "        self.log('acc_epoch', {'train': acc}, on_step=False, on_epoch=True)\n",
    "        self.log('train_loss', loss, prog_bar=False)\n",
    "        self.log('train_acc', acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, acc = self.shared_step(batch)\n",
    "        self.log('loss_epoch', {'val': loss}, on_step=False, on_epoch=True)\n",
    "        self.log('acc_epoch', {'val': acc}, on_step=False, on_epoch=True)\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, acc = self.shared_step(batch)\n",
    "        self.log('loss_epoch', {'test': loss}, on_step=False, on_epoch=True)\n",
    "        self.log('acc_epoch', {'test': acc}, on_step=False, on_epoch=True)\n",
    "        self.log('test_loss', loss, prog_bar=True)\n",
    "        self.log('test_acc', acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    # Allow brains-py to do constrained optimisation\n",
    "    def training_step_end(self, outputs):\n",
    "        if 'constraint_weights' in dir(self.model):\n",
    "            self.model.constraint_weights()\n",
    "        return outputs\n",
    "    \n",
    "    # Make pretty the progress bar\n",
    "    def get_progress_bar_dict(self):\n",
    "        # don't show the version number\n",
    "        items = super().get_progress_bar_dict()\n",
    "        items.pop(\"v_num\", None)\n",
    "        return items\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fba408a",
   "metadata": {},
   "source": [
    "## 5. Creating a vanilla pytorch model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f69e63",
   "metadata": {},
   "source": [
    "A custom model can be created in pytorch by implementing a child class of nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b9be29de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"4.finding_functionality/lenet3.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "Image(url= \"4.finding_functionality/lenet3.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1944661d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class FlattenView(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FlattenView, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        #return x.view(x.shape[0], -1)\n",
    "        return x.flatten(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "328cce78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    \n",
    "    # Constructor: Initialisation stage\n",
    "    def __init__(self, mode='nn'):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.name = 'LeNet'\n",
    "\n",
    "        # First convolution layer\n",
    "        #                     (in_channels, out_channels, kernel_size)\n",
    "        self.conv1 = nn.Conv2d(1          ,6            , 3)\n",
    "        \n",
    "        \n",
    "        # Second convolution layer\n",
    "        #                     (in_channels, out_channels, kernel_size)\n",
    "        self.conv2 = nn.Conv2d(6          ,16           , 3)\n",
    "        \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Sequential(FlattenView(), \n",
    "                                nn.Linear(400, 120),\n",
    "                                nn.ReLU(), \n",
    "                                nn.Linear(120, 84), \n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(84, 10))\n",
    "        # Activation function\n",
    "        self.act = nn.ReLU()\n",
    "        \n",
    "        # Pooling layer\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.act(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x # Logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db71f353",
   "metadata": {},
   "source": [
    "## 6. Training the vanilla model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179a44c5",
   "metadata": {},
   "source": [
    "### Hyperparemeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e0568b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2efd6c4",
   "metadata": {},
   "source": [
    "### Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c05e5061",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 2508835240\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import seed_everything\n",
    "\n",
    "seed = 2508835240\n",
    "seed = seed_everything(seed, workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c25fff14",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = MNISTDataModule(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5eb797d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "        monitor='val_acc', filename='sample-mnist-{val_acc:.3f}', mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "458591be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "afad657c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wrapper = TrainerMNIST(model, batch_size=batch_size, learning_rate=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6290a488",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "/home/unai/anaconda3/envs/bspy/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1294: UserWarning: GPU available but not used. Set the gpus flag in your trainer `Trainer(gpus=1)` or script `--gpus=1`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(gpus=0,max_epochs=5,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    deterministic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0c70fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=lightning_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9bfe858b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/unai/anaconda3/envs/bspy/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
      "  rank_zero_deprecation(\n",
      "\n",
      "  | Name  | Type  | Params\n",
      "--------------------------------\n",
      "0 | model | LeNet | 60.1 K\n",
      "--------------------------------\n",
      "60.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "60.1 K    Total params\n",
      "0.240     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validation sanity check'), FloatProgress(value=1.0, bar_style='info', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 2508835240\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "727f878e2f5845f7b6f67056a1dbec3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/unai/anaconda3/envs/bspy/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1046: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model_wrapper, datamodule=mnist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b38d13d",
   "metadata": {},
   "source": [
    "## 6. Modifying LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "853d84ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"4.finding_functionality/lenetmodified.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "Image(url= \"4.finding_functionality/lenetmodified.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ea51b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class LeNetModified(nn.Module):\n",
    "    \n",
    "    # Constructor: Initialisation stage\n",
    "    def __init__(self, mode='nn'):\n",
    "        super(LeNetModified, self).__init__()\n",
    "        self.name = 'LeNetModified'\n",
    "\n",
    "        # First convolution layer\n",
    "        #                     (in_channels, out_channels, kernel_size)\n",
    "        self.conv1 = nn.Conv2d(1          ,6            , 3)\n",
    "        self.bn1 = nn.BatchNorm2d(6) # Same as out channels\n",
    "        \n",
    "        # Second convolution layer\n",
    "        #                     (in_channels, out_channels, kernel_size)\n",
    "        self.conv2 = nn.Conv2d(6          ,16           , 3)\n",
    "        self.bn2 = nn.BatchNorm2d(16) # Same as out channels\n",
    "        \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Sequential(FlattenView(), \n",
    "                                nn.Linear(400, 120),\n",
    "                                nn.ReLU(), \n",
    "                                nn.Linear(120, 84), \n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(84, 10))\n",
    "        # Activation function\n",
    "        self.act = nn.Sigmoid() # Changed activation function\n",
    "        \n",
    "        # Pooling layer\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x) # New line\n",
    "        x = self.act(x) \n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x) # New line\n",
    "        x = self.act(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x # Logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885e4640",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_modified = LeNetModified()\n",
    "model_modified_wrapper = TrainerMNIST(model_modified, batch_size=batch_size, learning_rate=lr)\n",
    "trainer = pl.Trainer(gpus=1,max_epochs=5,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    deterministic=True)\n",
    "trainer.fit(model_modified_wrapper, datamodule=mnist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1e0de4",
   "metadata": {},
   "source": [
    "For this exercise, the Genetic Algorithm will be used, as this is a fast way to explore functionality on devices directly on-chip. The particularities of each config is explained below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5772b3c0",
   "metadata": {},
   "source": [
    "## 7. Using convolutions with DNPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f112a809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_configs():\n",
    "    configs = {}\n",
    "    configs[\"model_data_path\"] = \"./training_data.pt\"  # \"./tmp/models/training_data_new_without_clipping.pt\"  #\"./tmp/models/training_data.pt\"\n",
    "    configs[\"processor_type\"] = \"simulation\"\n",
    "    configs[\"waveform\"] = {}\n",
    "    configs[\"waveform\"][\"plateau_length\"] = 1\n",
    "    configs[\"waveform\"][\"slope_length\"] = 0\n",
    "    return configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c4c530",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from brainspy.processors.processor import Processor\n",
    "from brainspy.processors.modules.conv import DNPUConv2d\n",
    "\n",
    "class LeNetDNPU(nn.Module):\n",
    "    \n",
    "    # Constructor: Initialisation stage\n",
    "    def __init__(self, mode='nn'):\n",
    "        super(LeNetDNPU, self).__init__()\n",
    "        self.name = 'LeNetDNPU'\n",
    "        \n",
    "        ###############################################################\n",
    "        # Declare a processor\n",
    "        configs = get_node_configs()\n",
    "        model_data = torch.load(configs['model_data_path'])\n",
    "        self.processor_base = Processor(configs, model_data['info'],\n",
    "                         model_data['model_state_dict'])\n",
    "        \n",
    "        # Select data input indices of each DNPU\n",
    "        data_input_indices_list = [[2, 3, 4]] * 3\n",
    "        ###############################################################\n",
    "        \n",
    "        # First convolution layer\n",
    "        #            nn.Conv2d(in_channels, out_channels, kernel_size)\n",
    "        self.conv1 = DNPUConv2d(self.processor_base, data_input_indices_list,\n",
    "                               1          ,6            , 3)\n",
    "        self.bn1 = nn.BatchNorm2d(6) # Same as out channels\n",
    "        \n",
    "        # Second convolution layer\n",
    "        #            nn.Conv2d(in_channels, out_channels, kernel_size)\n",
    "        self.conv2 = DNPUConv2d(self.processor_base, data_input_indices_list,\n",
    "                               6          ,16            , 3)\n",
    "        self.bn2 = nn.BatchNorm2d(16) # Same as out channels\n",
    "        \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Sequential(FlattenView(), \n",
    "                                nn.Linear(400, 120),\n",
    "                                nn.ReLU(), \n",
    "                                nn.Linear(120, 84), \n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(84, 10))\n",
    "        # Activation function\n",
    "        self.act = nn.Sigmoid() # Changed activation function\n",
    "        \n",
    "        # Pooling layer\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        \n",
    "        ###############################################################\n",
    "        self.conv1.add_input_transform([0, 1])\n",
    "        self.conv2.add_input_transform([0, 1])\n",
    "        ###############################################################\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x) # New line\n",
    "        x = self.act(x) \n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x) # New line\n",
    "        x = self.act(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x # Logits\n",
    "    \n",
    "    ###############################################################\n",
    "    def swap(self, configs, info):\n",
    "        self.processor_base.swap(configs, info)\n",
    "    ###############################################################\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6ba88e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "\n",
    "model_modified = LeNetDNPU().to('cpu')\n",
    "model_modified_wrapper = TrainerMNIST(model_modified, batch_size=batch_size, learning_rate=lr).to('cpu')\n",
    "\n",
    "trainer = pl.Trainer(gpus=0, max_epochs=5,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    deterministic=True)\n",
    "\n",
    "trainer.fit(model_modified_wrapper, datamodule=mnist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e72993b",
   "metadata": {},
   "source": [
    "## 8. Testing convolutions on real DNPU hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d951a191",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function tqdm.__del__ at 0x7fecaabcc0d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/unai/anaconda3/envs/bspy/lib/python3.8/site-packages/tqdm-4.51.0-py3.8.egg/tqdm/std.py\", line 1128, in __del__\n",
      "    self.close()\n",
      "  File \"/home/unai/anaconda3/envs/bspy/lib/python3.8/site-packages/tqdm-4.51.0-py3.8.egg/tqdm/notebook.py\", line 266, in close\n",
      "    self.sp(close=True)\n",
      "AttributeError: 'tqdm' object has no attribute 'sp'\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: all CUDA-capable devices are busy or unavailable\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8868/2180799824.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'4.finding_functionality/sample-mnist-val_acc=0.98-v2.ckpt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/bspy/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    710\u001b[0m                     \u001b[0mopened_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_position\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    713\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bspy/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1044\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bspy/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m             \u001b[0mnbytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumel\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m             \u001b[0mload_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bspy/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m    999\u001b[0m         \u001b[0;31m# stop wrapping with _TypedStorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m         loaded_storages[key] = torch.storage._TypedStorage(\n\u001b[0;32m-> 1001\u001b[0;31m             \u001b[0mwrap_storage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1002\u001b[0m             dtype=dtype)\n\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bspy/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bspy/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    156\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mstorage_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bspy/lib/python3.8/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, non_blocking, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bspy/lib/python3.8/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_new\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;31m# We may need to call lazy init again if we are a forked child\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m     \u001b[0;31m# del _CudaBase.__new__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_CudaBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: all CUDA-capable devices are busy or unavailable\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "results = torch.load('4.finding_functionality/sample-mnist-val_acc=0.98-v2.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2635225",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0122d823",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['state_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3934c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = LeNetDNPU()\n",
    "my_model.load_state_dict(results['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443a1c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor_configs = {\n",
    "    \"processor_type\" : 'cdaq_to_cdaq', # There are four different processor types: 'simulation', 'cdaq_to_cdaq', 'cdaq_to_nidaq', 'simulation_debug'. The first \n",
    "    'input_indices': [3,6], # It specifies what indices will be taken as data input. These correspond to the indices of the activation channels inside the instruments setup configuration. \n",
    "    'waveform': { # The waveform determines the number of points that will be used to represent a single point. More information about waveforms can be found at Section 5.1 Waveforms: https://github.com/BraiNEdarwin/brains-py/wiki/A.-Introduction\n",
    "        'plateau_length' : 30, \n",
    "        'slope_length' : 30\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e61d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_configs = {\n",
    "        'inverted_output': True, # Whether if the op-amp circuit to amplify the output of the DNPU applies an inversion or not.\n",
    "        'amplification': [41], # Indicates the amplification correction factor that will be applied to obtain the real current measurement from the setup. More information about this can be found in Section 5.3 of the introduction of brains-py wiki: https://github.com/BraiNEdarwin/brains-py/wiki/A.-Introduction\n",
    "        'instruments_setup':{ \n",
    "            'multiple_devices': False, # Indicates whether if the setup is using a PCB with multiple devices or not.\n",
    "            'trigger_source': 'cDAQ1/segment1', # Triggering signal to be sent for reading synchronisation. You can check for this signal for your setup on the NIMax app.\n",
    "            'average_io_point_difference': True, # If number of points read from the device is different from the number of points written to the device due to a difference in their\n",
    "                                                # sampling frequencies, this variable indicates if there should be an averaging so that the input and output have the same length.\n",
    "            'activation_instrument': 'cDAQ1Mod3', # Main module used for sending voltage signals to the DNPU \n",
    "            'activation_sampling_frequency': 1000, # Number of samples that will be written to the DNPU in one second.\n",
    "            'activation_channels': [6,0,1,5,2,4,3], # Channels of the module that will be used for sending signals the device. \n",
    "            'activation_voltage_ranges': # Maximum minimum and maximum voltage ranges that will be allowed to be sent to the DNPU, per electrode. Dimensions (Electrode_no, 2)\n",
    "              [\n",
    "                [-0.7,1.2],[-0.3,0.4],[-0.7,1.2],[-0.8,1.1],[-0.6,1.1],[-0.3,0.5],[-0.7,1.1]\n",
    "              ],\n",
    "            'readout_instrument': 'cDAQ1Mod4', # Main module used for receiving voltage signals from the DNPU (after the op-amp) \n",
    "            'readout_sampling_frequency': 1000, # Number of samples that will be read from the DNPU in one second\n",
    "            'readout_channels': [0], # Channels of the module that will be used for reading signals from the device. \n",
    "            'activation_channel_mask': [1, 1, 1, 1, 1, 1, 1] # Whether if all the channels connected to the device electrodes would be used or not. 1 for enabling its use, 0 for disabling it. When disabled, the channels will not be declared.\n",
    "        }\n",
    "    \n",
    "    }\n",
    "\n",
    "processor_configs['driver'] = driver_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779b96ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = torch.load(\"./training_data.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23c54af",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.swap(processor_configs, model_data['info'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96bbfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bb9eaffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"4.finding_functionality/processor.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "Image(url= \"4.finding_functionality/processor.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a05ec96",
   "metadata": {},
   "source": [
    " - NNModel: Pytorch model (trained smg)\n",
    " - SoftwareProcessor:\n",
    "    * Noise\n",
    "    * Amplification\n",
    "    * Clipping\n",
    " - Processor: \n",
    "    * Handle changes from SurrogateModel to HardwareModel    \n",
    " - DNPU:\n",
    "    * Declares control voltages as learnable parameters\n",
    " - Driver: Connect to NISetup    \n",
    " - Hardware model:\n",
    "    * Apply slopes\n",
    "    * Transform to numpy\n",
    "    * Apply mask\n",
    "    * Transform to pytorch\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
